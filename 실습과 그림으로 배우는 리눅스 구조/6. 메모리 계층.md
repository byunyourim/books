
# 메모리 장치의 계층 구조
<img width="912" alt="스크린샷 2024-09-16 오후 2 13 15" src="https://github.com/user-attachments/assets/981469e1-f05c-47e7-b3bb-da7118cb9886">


#### 크기와 성능에는 어떤 차이가 있을까?  


#### 이런 차이를 고려하여 하드웨어, 리눅스는 어떤 구조인가?


<br>

# 캐시 메모리
### 컴퓨터의 동작 흐름
1. 명령어를 바탕으로 메모리에서 레지스터로 데이터를 읽는다.
2. 레지스터에 있는 데이터를 바탕으로 계산한다.
3. 계산 결과를 메모리에 기록한다.


#### 레이턴시?
메모리에 접근하는 데 걸리는 시간  


<br>

하드웨어는 레지스터에서 계산하는 평균 시간보다 메모리에 접근하는 데 걸리는 시간이 극도로 느리다.  
캐시메모리는 이런 레지스터 안에서 계산하는 것과 메모리에 접근하는 것의 시간 차이를 메우는 것이 필요합니다.  

캐시 메모리로부터 레지스터에 접근하는 레이턴시는 메모리에 접근할 때와 비교해 접근 속도가 수십 배 빠르다.
캐시 메모리는 일반적으로 CPU에 내장되어 있지만 CPU 바깥에 있는 캐시 메모리도 있다.
  
- 캐시 메모리의 처리는 커널을 통하지 않고 하드웨어 안에서 처리된다.
- 메모리에서 레지스터로 데이터를 읽어올 때, 일단 캐시 메모리에 읽어온 뒤 다시 레지스터로 읽어 들인다.
- 이땨, 읽어오는 크기는 CPU에서 정한 '캐시 라인 사이즈' 만큼이다.

##### 캐시 라인 사이즈 : 10바이트, 캐시 메모리 사이즈 : 50바이트, 레지스터가 10바이트씩 2개(R0, R1)
R0에 메모리 주소 300번지의 데이터를 읽는 경우
<img width="899" alt="스크린샷 2024-09-16 오후 2 40 27" src="https://github.com/user-attachments/assets/10bdd212-e724-4d6f-9ad3-033595cd0e7f">

<br>


#### 이후에 CPU가 주소 300번지의 데이터를 다시 읽으려면 캐시 메모리에 접근하면 된다.
<img width="913" alt="스크린샷 2024-09-16 오후 2 39 57" src="https://github.com/user-attachments/assets/e8c8a76b-c0f1-4642-9c97-1aee10f0e617">


#### R0에 값을 덮어쓰는 경우 (0000->xxxx)
<img width="906" alt="스크린샷 2024-09-16 오후 2 44 11" src="https://github.com/user-attachments/assets/acb032bd-efa4-440c-8817-6bbbc96138eb">

아래와 같이 변경된 데이터를 캐시메모리에 적는다. 데이터를 쓰는 단위도 캐시 라인 사이즈이다.  
이때 캐시 라인은 메모리로부터 읽어 들인 데이터가 변경되었음을 나타내는 플래그를 표시한다. 이러한 플러그가 표시된 캐시라인을 더티(dirty)라 한다.  
<img width="918" alt="스크린샷 2024-09-16 오후 2 46 50" src="https://github.com/user-attachments/assets/679331d5-9b59-4287-b11d-20bb31dca761">


<br>

이 더티 플래그가 붙은 데이터는 캐시메모리에 써넣은 시점보다 나중에 백그라운드 처리로 메모리에 다시 기록된다.
이에 따라 캐시라인은 더티가 아니게 된다.
<img width="914" alt="스크린샷 2024-09-16 오후 2 52 47" src="https://github.com/user-attachments/assets/33f3f124-4f1c-4cd9-afe7-b18e1f8d654b">



<br>

<img width="914" alt="스크린샷 2024-09-16 오후 3 05 06" src="https://github.com/user-attachments/assets/82371faf-7ac2-41c6-ad11-c0d72966e115">



<br>

## 캐시 메모리가 가득 찬 경우
캐시 메모리가 가득 찬 경우, 캐시 메모리에 존재하지 않는 데이터를 추가로 읽으면 기존의 캐시 메모리 중 1개를 파기한다.  
<img width="890" alt="스크린샷 2024-09-16 오후 3 17 58" src="https://github.com/user-attachments/assets/fbd00d4c-5b02-4e8c-8b8f-5fe986ac658e">

<br>

파기 후, 해당하는 주소의 데이터를 캐시 라인에 복사한다.
<img width="897" alt="스크린샷 2024-09-16 오후 3 19 16" src="https://github.com/user-attachments/assets/3b46a605-efdb-4b57-934b-f8af5b40d335">

파기하는 캐시가 더티인 경우 대응되는 메모리에 덮어쓴 다음 버린다.  
캐시 메모리가 가득 차고 모든 캐시 라인이 더티라면 메모리 접근을 할 때마다 캐시 라인 안의 데이터가 자주 바뀌게 되는 스래싱(thrashing)이 발생하여 성능이 감소할 수 있다.

<br>

## 계층형 캐시 메모리
x86_64 아키텍처의 CPU는 캐시 메모리가 계층형 구조로 되어 있다.  
각 계층은 사이즈, 레이턴시, 어느 논리 CPU 사이에 공유하는가 등이 다르다.  



계층형 구조를 구성하는 각 캐시 메모리는 L1, L2, L3등의 이름이 붙는다.  
CPU 마다 어느 레벨의 캐시가 존재하는지 다르며, 가장 레지스터에 가깝고 용량이 작으며, 빠른 것은 L1 캐시이다. 번호가 커질수록 레지스터로부터 멀어지며 용량이 커지고 속도가 느리다.   

캐시 메모리의 정보는 'sys/devices/system/cpu/cpu0/cache/index0/*' 디렉터리에 있다.
- type : 캐시할 데이터의 종류, Data, Code, Unified
- shared_cpu_list : 캐시를 공유할 논리 CPU 목록
- size : 파일 사이즈
- coherency_line_size : 캐시 라인 사이즈

<br>

## 메모리 참조의 국소성  
프로세스의 데이터가 전부 캐시에 있는 동안에는 데이터에 접근하는 속도는 메모리에 접근하는 속도가 아닌, **캐시에 접근하는 속도**이다
- **시간 국소성** : 특정 시점에에서 접근하는 데이터는 가까운 미래에 다시 접근할 가능성이 크다. (루프 처리 중인 코드 영역)
- **공간 국소성** : 특정 시점에섯 어떤 데이터에 접근하면 그 데이터와 가까운 주소에 있는 데이터에 접근할 확률이 높다. (배열 전체 검색)

  
프로세스는 자신이 획득한 메모리의 총량보다 훨씬 좁은 범위의 메모리에 접근하는 성향이 있다.  
이 좁은 범위를 캐시 메모리의 사이즈가 커버할 수 있으면 성능이 좋은 것이다.

<br>

## 정리
캐시 메모리의 효과를 높이기 위해서는
프로그램이 자주 사용하는 메모리의 데이터가 캐시 메모리에 상주할 수 있도록 최적화해야 한다.

캐시 메모리는 용략이 작기 때문에 많은 양의 데이터를 저장할 수 없다. 프로그램이 한 번에 너무 많은 메모리 범위에 접근하면 캐시에서 기존 데이터를 지우고 새로운 데이터를 불러와야 한다.(캐시 미스)  
따라서 단위 시간 내에 사용하는 메모리 범위(주소 범위)를 줄이면 캐시에서 더 많은 데이터를 유지할 수 있어, 캐시 히트율을 높이고 메모리 접근 속도를 빠르게 할 수 있다.

한편, 시스템 설정을 변경했을 때 프로그램의 성능이 크게 나빠진 경우 프로그램의 데이터가 캐시 메모리에 전부 들어가지 않았을 가능성이 있다.

<br><br><br>

# Translation Lookaside Buffer
가상 주소의 데이터 접근
1. 물리 메모리상에 존재하는 페이지 테이블을 참고하여 가상 주소를 물리 주소로 변환한다.
2. 1에서 구한 물리 메모리에 접근한다.(캐시 메모리 사용)

1번의 동작은 물리 메모리 상에 있는 피에지 테이블에 접근해야 하기 때문에 캐시가 동작할 수 없다.  
CPU에는 가상 주소에서 물리 주소로의 변환표를 보관하고, 캐시 메모리와 똑같이 고속으로 접근 가능한 TLB라는 영역을 사용해 고속화한다.

<br><br><br>

# 페이지 캐시
저장장치의 데이터에 접근하는 속도는 매우 느리다.
저장장치에 저장된 데이터는 먼저 **메인 메모리(RAM)**로 로드된 후, CPU가 해당 데이터를 메모리에서 처리할 수 있다.
저장장치와 메모리 사이의 데이터 이동은 입출력(I/O) 장치, 메모리 컨트롤러에 의해 관리되며, 이를 통해 저장된 데이터가 메모리로 로드된다.

<br>

이 속도의 차이를 줄이기 위해 커널에 페이지 캐시라는 기능이 존재한다.
#### 특징
- 캐시 메모리와 비슷
- 저장 장치 내의 파일 데이터를 메모리에 캐싱
- 페이지 단위로 데이터를 다룬다.

#### 동작
  1. 프로세스가 파일의 데이터를 읽어 들인다.
  2. 커널은 프로세스의 메모리에 파일의 데이터를 직접 복사하는 것이 아닌 , 일단 커널의 메모리 내에 있는 페이지 캐시 영역에 복사한 뒤 이 데이터를 메모리에 복사한다.
  
우선  페이지 캐시에 복사한다.  
<img width="831" alt="스크린샷 2024-09-16 오후 4 34 39" src="https://github.com/user-attachments/assets/aa120ce0-29b9-4921-b48c-c0aafc030311">

페이지 캐시에 캐싱된 파일에 대한 정보를 보관한다.
<img width="853" alt="스크린샷 2024-09-16 오후 4 34 56" src="https://github.com/user-attachments/assets/1c00c275-cf3d-45ec-9b9c-ba76a612a326">

그리고 페이지 캐시에 존재하는 데이터를 다시 읽으면 커널은 페이지 캐시의 데이터를 돌려준다.

이 방법은 저장 장치에 접근하느 경우에 비해 훨씨 빠른 속도로 처리된다.  
또한 페이지 캐시는 전체 프로세스 공유의 자원이기때문에 읽어 들인 프로세스는 최초에 파일 데이터에 접근한 프로세스와다른 프로세스여도 문제 없다.

<br><br><br>

# 동기화된 쓰기
페이지 캐시에 더티 페이지가 있는 상태로 시스템의 전원이 강제로 꺼진다면 어떤 일이 벌어질까요?

전원이 강제로 종료되면 페이지 캐시의 데이터는 사라진다. 방지하기 위해서는 open() 시스템 콜로 파일을 열 때 'O_SYNC'플래그를 설정한다.  
이렇게 하면 후에 write() 시스템 콜을 수행할 때마다 데이터는 페이지 캐싯 외에 저장 장치에도 동기화되어 쓰기가 수행된다.
<br><br><br>

# 버퍼 캐시
파일시스템을 사용하지 않고 디바이스 파일을 이용하여 저장 장치에 직접 접근하는 목적으로 사용된다  
페이지 캐시와 버퍼 캐시를 합쳐 저장 장치 안의 데이터를 메모리에 넣는 방식이다.
<br><br><br>


# 튜닝 파라미터
페이지 캐시 제어  
시스템 성능에 페이지 캐시의 영향을 확인하는 용도로 편리하다.
- vm.dirty_writeback_centisecs
- vm.dirty_background_ratio : 
- vm.dirty_bytes : 바이트 단위 지정
- vm.dirty_ratio : 지정된 퍼센트를 초과하면 프로세스에 의한 파일에 쓰기의 연장으로 동기적 라이트 백 수행

<br><br><br>

# 정리
파일의 데이터가 페이지 캐시에 있다면 파일의 접근이 매우 빨라진다.  
따라서, 시스템에 접근하는 파일의 사이즈, 물리 메모리 양이 중요하다.  

파일의 데이터가 페이지 캐시에 제대로 들어가지 못한 경우, 시스템의 성능이 느려질 수 있다.  


#### 페이지 캐시에 관한 통계 정보
- sar -B
- sar -d -p


<br><br><br>

# 하이퍼 스레드
CPU 사용 시간 중 대부분은 메모리, 캐시 메모리로부터 데이터를 기다리는 일에 사용된다.
<img width="919" alt="스크린샷 2024-09-16 오후 4 14 51" src="https://github.com/user-attachments/assets/bde9283d-c8df-4249-98f7-a49f851fc8b9">

이러한 대기 시간으로 낭비되는 CPU의 자원을 하이퍼스레드 기능으로 유효하게 활용할 수 있다.  

CPU 코어 안의 레지스터 등 일부 자원을 여러 개 준비하고, 시스템 입장에서는 각각 논리 CPU로써 인식되는 하이퍼스레드라는 단위로 분할되는 하드웨어 기능  

각각의 하이퍼스레드는 특정 조건 아래에서 여러 개가 동시에 실행 가능하다.  


## 하이퍼스레드 기능을 껐을 때
## 하이퍼스레드 기능을 켰을 때
